# -----------------------------
# HorizontalPodAutoscaler (HPA): automatically scales the "inference" Deployment
# based on CPU usage.
# Requires Metrics Server installed in the cluster to work.
# -----------------------------
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: inference-hpa            # Name of the HPA resource
  namespace: pm                  # Namespace where HPA is created
spec:
  # This tells the HPA which workload to scale up/down
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: inference              # Target Deployment name to autoscale

  minReplicas: 1                 # Minimum number of Pods (won't scale below this)
  maxReplicas: 5                 # Maximum number of Pods (won't scale above this)

  # Scaling rule: watch CPU usage across Pods
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50   # Target average CPU usage (% of requested CPU)
                                # If average > 50%, HPA scales up
                                # If average < 50%, HPA may scale down
