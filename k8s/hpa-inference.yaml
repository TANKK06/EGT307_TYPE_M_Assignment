apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: inference-hpa              # HPA name (autoscaler for inference deployment)
  namespace: pm                    # Namespace where the inference deployment lives
spec:
  scaleTargetRef:
    apiVersion: apps/v1            # API version of the target resource
    kind: Deployment               # We are scaling a Deployment
    name: inference                # Deployment name to scale
  minReplicas: 1                   # Minimum number of inference pods
  maxReplicas: 5                   # Maximum number of inference pods
  metrics:
  - type: Resource                 # Scale based on a resource metric
    resource:
      name: cpu                    # Use CPU utilization
      target:
        type: Utilization          # Target is % of requested CPU (IMPORTANT)
        averageUtilization: 50     # Try to keep average CPU around 50%
