apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference                         # Inference API deployment
  namespace: pm                           # Namespace where inference runs
spec:
  replicas: 1                             # Starting replicas (HPA will adjust)
  selector:
    matchLabels:
      app: inference                      # Must match pod template labels
  template:
    metadata:
      labels:
        app: inference                    # Label used by Service + HPA
    spec:
      # Init container seeds the model into the PVC if it does not exist yet
      initContainers:
      - name: seed-model
        image: docker.io/kaykit/pm-inference:v1
        imagePullPolicy: IfNotPresent
        command:
        - sh
        - -c
        - >
          if [ ! -f /app/model_store/best_model.joblib ];
          then echo 'Seeding model into PVC';
               cp -v /app/model/best_model.joblib /app/model_store/best_model.joblib;
          else echo 'Model already present';
          fi
        volumeMounts:
        - name: model-storage
          mountPath: /app/model_store      # Same mount as main container so file is shared via PVC

      containers:
      - name: inference                    # Main inference container
        image: docker.io/kaykit/pm-inference:v1
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8000              # API port

        # Load service URLs and non-sensitive config
        envFrom:
        - configMapRef:
            name: pm-config

        # App-specific env var for where to load the model from (PVC path)
        env:
        - name: MODEL_PATH
          value: /app/model_store/best_model.joblib

        # Mount the model PVC into the container
        volumeMounts:
        - name: model-storage
          mountPath: /app/model_store

        # Readiness probe: pod receives traffic only when this passes
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

        # Liveness probe: restart container if it becomes unhealthy
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 15
          periodSeconds: 10

        # Resource requests/limits (HPA uses requests.cpu for Utilization scaling)
        resources:
          requests:
            cpu: 100m                      # Baseline CPU request (used in HPA % calculation)
            memory: 256Mi
          limits:
            cpu: 500m                      # Upper limit
            memory: 512Mi

      volumes:
      - name: model-storage
        persistentVolumeClaim:
          claimName: model-pvc             # PVC that stores the model file persistently
---
apiVersion: v1
kind: Service
metadata:
  name: inference                         # Internal DNS name: inference.pm.svc.cluster.local
  namespace: pm
spec:
  selector:
    app: inference                        # Routes traffic to inference pods
  ports:
  - port: 8000                            # Service port inside cluster
    targetPort: 8000                      # Container port
  type: ClusterIP                         # Internal-only access
